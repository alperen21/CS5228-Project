{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_votes</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>current_players</th>\n",
       "      <th>total_reviews</th>\n",
       "      <th>total_positive</th>\n",
       "      <th>total_negative</th>\n",
       "      <th>score</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_tokenised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>219640</td>\n",
       "      <td>Chivalry: Medieval Warfare</td>\n",
       "      <td>it's not dark souls but it's alright I guess.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.025955</td>\n",
       "      <td>19</td>\n",
       "      <td>22203</td>\n",
       "      <td>18075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.79864</td>\n",
       "      <td>['it', 'not', 'dark', 'souls', 'but', 'it', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>219640</td>\n",
       "      <td>Chivalry: Medieval Warfare</td>\n",
       "      <td>Tired of those first person shooters? Want a m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>19</td>\n",
       "      <td>22203</td>\n",
       "      <td>18075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.79864</td>\n",
       "      <td>['Tired', 'of', 'those', 'first', 'person', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>219640</td>\n",
       "      <td>Chivalry: Medieval Warfare</td>\n",
       "      <td>Always fun hacking people legs off and listeni...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.863879</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>19</td>\n",
       "      <td>22203</td>\n",
       "      <td>18075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.79864</td>\n",
       "      <td>['Always', 'fun', 'hacking', 'people', 'legs',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>219640</td>\n",
       "      <td>Chivalry: Medieval Warfare</td>\n",
       "      <td>With one mighty swing of my pole hammer, I got...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.367085</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>19</td>\n",
       "      <td>22203</td>\n",
       "      <td>18075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.79864</td>\n",
       "      <td>['With', 'one', 'mighty', 'swing', 'of', 'my',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>219640</td>\n",
       "      <td>Chivalry: Medieval Warfare</td>\n",
       "      <td>There is nothing more satisfying than chopping...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935398</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>19</td>\n",
       "      <td>22203</td>\n",
       "      <td>18075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.79864</td>\n",
       "      <td>['There', 'is', 'nothing', 'more', 'satisfying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  app_id                    app_name  \\\n",
       "0           0  219640  Chivalry: Medieval Warfare   \n",
       "1           1  219640  Chivalry: Medieval Warfare   \n",
       "2           2  219640  Chivalry: Medieval Warfare   \n",
       "3           3  219640  Chivalry: Medieval Warfare   \n",
       "4           4  219640  Chivalry: Medieval Warfare   \n",
       "\n",
       "                                         review_text  review_score  \\\n",
       "0      it's not dark souls but it's alright I guess.             1   \n",
       "1  Tired of those first person shooters? Want a m...             1   \n",
       "2  Always fun hacking people legs off and listeni...             1   \n",
       "3  With one mighty swing of my pole hammer, I got...             1   \n",
       "4  There is nothing more satisfying than chopping...             1   \n",
       "\n",
       "   review_votes  admiration  amusement     anger  annoyance  ...   sadness  \\\n",
       "0             1    0.000234   0.000064  0.000130   0.000434  ...  0.000089   \n",
       "1             1    0.000028   0.000702  0.000800   0.016306  ...  0.001012   \n",
       "2             1    0.000075   0.863879  0.000055   0.000383  ...  0.000068   \n",
       "3             1    0.000517   0.000886  0.000229   0.000351  ...  0.003140   \n",
       "4             1    0.935398   0.000440  0.000291   0.000216  ...  0.000095   \n",
       "\n",
       "   surprise   neutral  current_players  total_reviews  total_positive  \\\n",
       "0  0.000078  0.025955               19          22203           18075   \n",
       "1  0.000246  0.014975               19          22203           18075   \n",
       "2  0.000111  0.000715               19          22203           18075   \n",
       "3  0.367085  0.013208               19          22203           18075   \n",
       "4  0.000114  0.008444               19          22203           18075   \n",
       "\n",
       "   total_negative     score   rating  \\\n",
       "0            4128  0.814079  0.79864   \n",
       "1            4128  0.814079  0.79864   \n",
       "2            4128  0.814079  0.79864   \n",
       "3            4128  0.814079  0.79864   \n",
       "4            4128  0.814079  0.79864   \n",
       "\n",
       "                                    review_tokenised  \n",
       "0  ['it', 'not', 'dark', 'souls', 'but', 'it', 'a...  \n",
       "1  ['Tired', 'of', 'those', 'first', 'person', 's...  \n",
       "2  ['Always', 'fun', 'hacking', 'people', 'legs',...  \n",
       "3  ['With', 'one', 'mighty', 'swing', 'of', 'my',...  \n",
       "4  ['There', 'is', 'nothing', 'more', 'satisfying...  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 41 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        1000 non-null   int64  \n",
      " 1   app_id            1000 non-null   int64  \n",
      " 2   app_name          975 non-null    object \n",
      " 3   review_text       1000 non-null   object \n",
      " 4   review_score      1000 non-null   int64  \n",
      " 5   review_votes      1000 non-null   int64  \n",
      " 6   admiration        1000 non-null   float64\n",
      " 7   amusement         1000 non-null   float64\n",
      " 8   anger             1000 non-null   float64\n",
      " 9   annoyance         1000 non-null   float64\n",
      " 10  approval          1000 non-null   float64\n",
      " 11  caring            1000 non-null   float64\n",
      " 12  confusion         1000 non-null   float64\n",
      " 13  curiosity         1000 non-null   float64\n",
      " 14  desire            1000 non-null   float64\n",
      " 15  disappointment    1000 non-null   float64\n",
      " 16  disapproval       1000 non-null   float64\n",
      " 17  disgust           1000 non-null   float64\n",
      " 18  embarrassment     1000 non-null   float64\n",
      " 19  excitement        1000 non-null   float64\n",
      " 20  fear              1000 non-null   float64\n",
      " 21  gratitude         1000 non-null   float64\n",
      " 22  grief             1000 non-null   float64\n",
      " 23  joy               1000 non-null   float64\n",
      " 24  love              1000 non-null   float64\n",
      " 25  nervousness       1000 non-null   float64\n",
      " 26  optimism          1000 non-null   float64\n",
      " 27  pride             1000 non-null   float64\n",
      " 28  realization       1000 non-null   float64\n",
      " 29  relief            1000 non-null   float64\n",
      " 30  remorse           1000 non-null   float64\n",
      " 31  sadness           1000 non-null   float64\n",
      " 32  surprise          1000 non-null   float64\n",
      " 33  neutral           1000 non-null   float64\n",
      " 34  current_players   1000 non-null   int64  \n",
      " 35  total_reviews     1000 non-null   int64  \n",
      " 36  total_positive    1000 non-null   int64  \n",
      " 37  total_negative    1000 non-null   int64  \n",
      " 38  score             1000 non-null   float64\n",
      " 39  rating            1000 non-null   float64\n",
      " 40  review_tokenised  1000 non-null   object \n",
      "dtypes: float64(30), int64(8), object(3)\n",
      "memory usage: 320.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import data from data directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#load data\n",
    "DATA_DIR = os.getcwd()+ '/Documents/GitHub/CS5228  Knowledge Discovery and Data Mining/CS5228-Project/'+ 'data/'\n",
    "files = []\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    #if file begins with 'steam_', then it is a steam reviews file\n",
    "    if file.startswith('steam_'):\n",
    "        files.append(file)\n",
    "    \n",
    "data = pd.concat([pd.read_csv(DATA_DIR + file) for file in files], ignore_index=True)\n",
    "\n",
    "display(data.head())\n",
    "display(data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "app_id              0\n",
       "app_name            0\n",
       "review_text         0\n",
       "review_score        0\n",
       "review_votes        0\n",
       "admiration          0\n",
       "amusement           0\n",
       "anger               0\n",
       "annoyance           0\n",
       "approval            0\n",
       "caring              0\n",
       "confusion           0\n",
       "curiosity           0\n",
       "desire              0\n",
       "disappointment      0\n",
       "disapproval         0\n",
       "disgust             0\n",
       "embarrassment       0\n",
       "excitement          0\n",
       "fear                0\n",
       "gratitude           0\n",
       "grief               0\n",
       "joy                 0\n",
       "love                0\n",
       "nervousness         0\n",
       "optimism            0\n",
       "pride               0\n",
       "realization         0\n",
       "relief              0\n",
       "remorse             0\n",
       "sadness             0\n",
       "surprise            0\n",
       "neutral             0\n",
       "current_players     0\n",
       "total_reviews       0\n",
       "total_positive      0\n",
       "total_negative      0\n",
       "score               0\n",
       "rating              0\n",
       "review_tokenised    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#remove rows with missing app_name\n",
    "data = data.dropna(subset=['app_name'])\n",
    "#check for missing values\n",
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ' a ' , 'wizard ' , 'staff ' , 'ha ' , ' a ' , 'knob ' , 'on ' , 'the ' , 'end ' , 'it ' , 'never ' , 'will ' , 'buckl ' , 'it ' , 'never ' , 'will ' , 'bend ' , 'he ' , 'cherish ' , 'it ' , 'and ' , 'he ' , 'call ' , 'it ' , 'hi ' , 'friend ' , 'and ' , 'he ' , 'frequent ' , 'take ' , 'it ' , 'in ' , 'hand ' , ' a ' , 'wizard ' , 'staff ' , ' i ' , 'the ' , 'sourc ' , 'of ' , 'hi ' , 'power ' , 'he ' , 'check ' , 'up ' , 'on ' , 'it ' , 'everi ' , 'hour ' , 'on ' , 'the ' , 'hour ' , 'and ' , 'he ' , 'never ' , 'surpris ' , 'when ' , 'it ' , 'turn ' , 'to ' , ' a ' , 'flower ' , 'the ' , 'fairest ' , 'throughout ' , 'all ' , 'the ' , 'land ' ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5228_proj/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5228_proj/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'far', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ab</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>abandon</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>abbr</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     word  tfidf\n",
       "0      0       aa    0.0\n",
       "1      0      aaa    0.0\n",
       "2      0       ab    0.0\n",
       "3      0  abandon    0.0\n",
       "4      0     abbr    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we want to perform tf-idf on the text data in the tokenized review column\n",
    "#first we need to preprocess the text data\n",
    "#do tf-idf on the review column\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "\n",
    "#download the stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#function to lemmatize the words\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_tokenize(text)]\n",
    "\n",
    "def stem_text(text):\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "#preprocess the text data\n",
    "documents = data['review_tokenised'].values\n",
    "#do autocorrection\n",
    "spell = Speller(lang='en')\n",
    "documents = [spell(doc) for doc in documents]\n",
    "\n",
    "#do stemming\n",
    "documents = [' '.join(stem_text(doc)) for doc in documents]\n",
    "#do lemmatization\n",
    "documents = [' '.join(lemmatize_text(doc)) for doc in documents]\n",
    "\n",
    "print(documents[np.random.randint(0, len(documents))])\n",
    "\n",
    "#remove punctuation\n",
    "documents = [re.sub(r'[^\\w\\s]', '', doc) for doc in documents]\n",
    "#remove numbers\n",
    "documents = [re.sub(r'\\d+', '', doc) for doc in documents]\n",
    "#remove accented characters\n",
    "documents = [doc.encode('ascii', 'ignore').decode() for doc in documents]\n",
    "\n",
    "#initialize the tfidf vectorizer\n",
    "stop_words = stopwords.words('english')\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, tokenizer=lemmatize_text)\n",
    "tfidf_matrix = tfidf.fit_transform(documents)\n",
    "\n",
    "#convert the tfidf matrix to a dataframe\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out(), index=data.index)\n",
    "tfidf_df_stack = tfidf_df.stack().reset_index().rename(columns={'level_0': 'index', 'level_1': 'word', 0: 'tfidf'})\n",
    "display(tfidf_df_stack.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1669208</th>\n",
       "      <td>351</td>\n",
       "      <td>first</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094286</th>\n",
       "      <td>441</td>\n",
       "      <td>sequel</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688199</th>\n",
       "      <td>566</td>\n",
       "      <td>frustrat</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973113</th>\n",
       "      <td>846</td>\n",
       "      <td>recommend</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416074</th>\n",
       "      <td>86</td>\n",
       "      <td>nice</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626914</th>\n",
       "      <td>552</td>\n",
       "      <td>ok</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054296</th>\n",
       "      <td>864</td>\n",
       "      <td>ok</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111935</th>\n",
       "      <td>233</td>\n",
       "      <td>good</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379891</th>\n",
       "      <td>933</td>\n",
       "      <td>free</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090740</th>\n",
       "      <td>872</td>\n",
       "      <td>confus</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842494</th>\n",
       "      <td>599</td>\n",
       "      <td>intro</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371811</th>\n",
       "      <td>77</td>\n",
       "      <td>good</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668582</th>\n",
       "      <td>561</td>\n",
       "      <td>early</td>\n",
       "      <td>0.971499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389583</th>\n",
       "      <td>81</td>\n",
       "      <td>awesom</td>\n",
       "      <td>0.928504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325378</th>\n",
       "      <td>920</td>\n",
       "      <td>year</td>\n",
       "      <td>0.926756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499874</th>\n",
       "      <td>526</td>\n",
       "      <td>clutch</td>\n",
       "      <td>0.925209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078598</th>\n",
       "      <td>648</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.919341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424982</th>\n",
       "      <td>510</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.919341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548806</th>\n",
       "      <td>751</td>\n",
       "      <td>horn</td>\n",
       "      <td>0.910598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351228</th>\n",
       "      <td>495</td>\n",
       "      <td>diablo</td>\n",
       "      <td>0.905013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289270</th>\n",
       "      <td>60</td>\n",
       "      <td>crack</td>\n",
       "      <td>0.899270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382271</th>\n",
       "      <td>79</td>\n",
       "      <td>minecraft</td>\n",
       "      <td>0.895618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004046</th>\n",
       "      <td>422</td>\n",
       "      <td>worm</td>\n",
       "      <td>0.890604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109123</th>\n",
       "      <td>444</td>\n",
       "      <td>suck</td>\n",
       "      <td>0.885955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205595</th>\n",
       "      <td>252</td>\n",
       "      <td>suck</td>\n",
       "      <td>0.885955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090715</th>\n",
       "      <td>228</td>\n",
       "      <td>ver</td>\n",
       "      <td>0.883456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918118</th>\n",
       "      <td>834</td>\n",
       "      <td>duke</td>\n",
       "      <td>0.875395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588038</th>\n",
       "      <td>978</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.873368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866157</th>\n",
       "      <td>604</td>\n",
       "      <td>great</td>\n",
       "      <td>0.872306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671255</th>\n",
       "      <td>996</td>\n",
       "      <td>ward</td>\n",
       "      <td>0.868736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index       word     tfidf\n",
       "1669208    351      first  1.000000\n",
       "2094286    441     sequel  1.000000\n",
       "2688199    566   frustrat  1.000000\n",
       "3973113    846  recommend  1.000000\n",
       "416074      86       nice  1.000000\n",
       "2626914    552         ok  1.000000\n",
       "4054296    864         ok  1.000000\n",
       "1111935    233       good  1.000000\n",
       "4379891    933       free  1.000000\n",
       "4090740    872     confus  1.000000\n",
       "2842494    599      intro  1.000000\n",
       "371811      77       good  0.999821\n",
       "2668582    561      early  0.971499\n",
       "389583      81     awesom  0.928504\n",
       "4325378    920       year  0.926756\n",
       "2499874    526     clutch  0.925209\n",
       "3078598    648       nice  0.919341\n",
       "2424982    510       nice  0.919341\n",
       "3548806    751       horn  0.910598\n",
       "2351228    495     diablo  0.905013\n",
       "289270      60      crack  0.899270\n",
       "382271      79  minecraft  0.895618\n",
       "2004046    422       worm  0.890604\n",
       "2109123    444       suck  0.885955\n",
       "1205595    252       suck  0.885955\n",
       "1090715    228        ver  0.883456\n",
       "3918118    834       duke  0.875395\n",
       "4588038    978        pop  0.873368\n",
       "2866157    604      great  0.872306\n",
       "4671255    996       ward  0.868736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sort the tfidf values in descending order\n",
    "tfidf_df_stack = tfidf_df_stack.sort_values(by=['tfidf'], ascending=False)\n",
    "display(tfidf_df_stack.head(30))\n",
    "#save the tfidf values to a csv file\n",
    "tfidf_df_stack.to_csv(DATA_DIR+'tfidf_'+files[0], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.047192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054593</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.069546</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.047676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027416</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.032190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6         7         8    9    ...       990  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  ...  0.000000   \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.014583  0.047192  0.0  ...  0.054593   \n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.037268  0.000000  0.0  ...  0.000000   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.017386  0.047676  0.0  ...  0.000000   \n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.000000  0.000000  0.0  ...  0.000000   \n",
       "\n",
       "        991       992       993       994       995  996       997       998  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "1  0.011867  0.069546  0.044506  0.027988  0.016855  0.0  0.024358  0.018097   \n",
       "2  0.000000  0.000000  0.048019  0.000000  0.026775  0.0  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.027416  0.022204  0.032190  0.0  0.021844  0.000000   \n",
       "4  0.000000  0.034337  0.017808  0.000000  0.000000  0.0  0.032964  0.000000   \n",
       "\n",
       "   999  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 975 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute the cosine similarity between the tfidf vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#we use linear_kernel instead of cosine_similarity because it is faster\n",
    "# linear_kernel is equivalent to cosine_similarity when the input data is normalized\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, columns=data.index, index=data.index)\n",
    "display(cosine_sim_df.head())\n",
    "\n",
    "#save the cosine similarity values to a csv file.\n",
    "# The rows and columns are the indices of the data dataframe\n",
    "cosine_sim_df.to_csv(DATA_DIR+'cosine_sim_'+files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the review data, the top 10 games similar to Company of Heroes - Legacy Edition are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256                                    PAYDAY 2\n",
       "460                                 Dying Light\n",
       "765              Call of Duty: Modern Warfare 3\n",
       "662                                  Bloons TD5\n",
       "61                           Grand Theft Auto V\n",
       "881                                 Psychonauts\n",
       "760    Star Wars: Battlefront 2 (Classic, 2005)\n",
       "625                 Sid Meier's Civilization VI\n",
       "695                             DARK SOULS™ III\n",
       "250                                    PAYDAY 2\n",
       "Name: app_name, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we will use the cosine similarity to recommend similar games using the review data\n",
    "#first we need to get the indices of the games\n",
    "indices = pd.Series(data.index, index=data['app_name'])\n",
    "#remove nan values\n",
    "indices = indices[~indices.index.isnull()]\n",
    "#drop the duplicate indices\n",
    "indices = indices[~indices.index.duplicated(keep='first')]\n",
    "\n",
    "#function to get the recommendations\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, indices=indices):\n",
    "    #if the title is not in the data, return an empty list\n",
    "    if title not in indices or title is None:\n",
    "        return 'game not found in the data'    \n",
    "    #get the index of the game that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    #get the pairwise similarity scores of all games with that game\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #sort the games based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #get the scores of the 10 most similar games\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    #get the game indices\n",
    "    game_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #return the top 10 most similar games\n",
    "    return data['app_name'].iloc[game_indices]    \n",
    "\n",
    "#test the function\n",
    "random_index = np.random.randint(0, len(data))\n",
    "str = data['app_name'].iloc[random_index]\n",
    "#cosine similarity is based on the review data\n",
    "print('Based on the review data, the top 10 games similar to', str, 'are:')\n",
    "get_recommendations(str, cosine_sim, indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5228_proj] *",
   "language": "python",
   "name": "conda-env-cs5228_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
